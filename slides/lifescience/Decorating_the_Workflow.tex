%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Decorating Workflows - Parameterization}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
    \frametitle{Outline}
    \begin{columns}[t]
        \begin{column}{.5\textwidth}
            \tableofcontents[sections={1-9},currentsection]
        \end{column}
        \begin{column}{.5\textwidth}
            \tableofcontents[sections={10-18},currentsection]
        \end{column}
    \end{columns}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{What is this about?}
   \begin{question}[Questions]
   	  \begin{itemize}
         \item How can a workflow be made really usable?
         \item How can I avoid changing the workflow source for every new input?
      \end{itemize}
   \end{question}
   \begin{docs}[Objectives]
   	 \begin{enumerate}
                      \item Learn how to make use of configuration files.  
                      \item Learn how to add parameters to your workflow.
     \end{enumerate}
   \end{docs}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Configuration Files}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Command Line vs. Configuration File}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \begin{docs}
  	\texttt{Snakemake} has an extensive command line interface (CLI). \emph{Everything} can be configured on the command line. In addition (almost) everything can be specified in a configuration file.
  \end{docs}
  \pause
  \begin{exampleblock}{Which parameter goes where? Some rules of thumb:}
    \begin{columns}[t]
      \begin{column}{0.5\textwidth}
        The CLI:
        \begin{itemize}
         \item frequently changing parameters
         \item short parameters
         \item default parameters
        \end{itemize}
      \end{column}
      \begin{column}{0.5\textwidth}
        The Config File:
        \begin{itemize}
         \item non-volantile parameters specific to your analysis (those which merit mentioning in paper should always go into a file)
         \item long parameters
         \item otherwise workflow specific parameters
        \end{itemize}
      \end{column}
    \end{columns}
  \end{exampleblock}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{The Configuration File}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{The \texttt{Snakemake} \texttt{resources} Section}
  \texttt{Snakemake} rules provide an additional \altverb{resource} section:
  \begin{lstlisting}[language=Python,style=Python]
rule <name>:
   ...
   resources:
      partition='parallel',
      mem_mb=1800,
      cpus_per_task=4
  \end{lstlisting}
  \begin{hint}
  	Note the \textbf{,}!
  \end{hint}
  \pause
  \begin{docs}
  	You \emph{may} define \emph{any} resource keyword within any rule.
  \end{docs}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{The \texttt{Snakemake} \texttt{resources} Section - its Downside}
  \begin{block}{Every Resource Spec needs a Change per Rule???}
   You might have noticed, this specification per rule is most untidy. \texttt{Snakemake}'s design principle is: ship workflows which run \emph{everywhere} \& \emph{every time}.
   \newline \pause
   Relax: Every bit we can specify:
   \begin{itemize}
    \item in a \texttt{Snakefile},
    \item on the command line,
    \item and re-usable in configuration files!
   \end{itemize}

  \end{block}

\end{frame} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{The Configuration File}
  If observed closely you have seen this file:\newline
            {\tiny \DTsetlength{0.2em}{1em}{0.2em}{0.4pt}{.6pt}
\texttt{\$ tree}
\dirtree{%
.1 /.
.2 config.
.3 samples.yaml .
.2 {other stuff}.
}}
 \pause
 \begin{docs}
 	You can store a yaml file with \emph{your} workflow configuration -- which may be combined with the desinger's configuration.
 \end{docs}
 \pause
 \begin{warning}
 	It is better to specify fully qualified paths to your data! The tilde is only there to make a point!
 \end{warning}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Using the Configuration File}
  To point to the configuration file, you can add a flag, e.\,g.:
  \begin{lstlisting}[language=Bash, style=Shell]
$ snakemake ... --configfile ./config/config.yaml  
  \end{lstlisting}
  Or, alternatively in your \texttt{Snakefile}:
  \begin{lstlisting}[language=Python,style=Python]
configfile: "config.yaml"
  \end{lstlisting}  
  \begin{question}
  	How do pick up resource parameters in out \texttt{Snakefile}?!
  \end{question}
\end{frame} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Working with Configuration Data}
  \begin{hint}
  	Remember: \texttt{Snakefile}s are Python files.
  \end{hint}
  \pause
  Given a file \altverb{config.yaml} with contents:
  \begin{lstlisting}[language=Python,style=Python]
samples:
    A: data/samples/A.fastq
    B: data/samples/B.fastq
  \end{lstlisting}
  we can read our samples within our workflow using
  \begin{lstlisting}[language=Python,style=Python]
configfile: "config.yaml"

rule bcftools_call:
    input:
        bam=expand("sorted_reads/{sample}.bam", 
            sample=@config["samples"]@),
        ...
  \end{lstlisting}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{A Comparison}
  \begin{lstlisting}[language=Python,style=Python,basicstyle=\footnotesize]
rule bcftools_call:
    input:
        fa="data/genome.fa",
        bam=expand("sorted_reads/{sample}.bam",
                   sample=config["samples"]),
        bai=expand("sorted_reads/{sample}.bam.bai",
                   sample=config["samples"])
  \end{lstlisting}
  To
  \begin{lstlisting}[language=Python,style=Python,basicstyle=\footnotesize]
rule bcftools_call:
    input:
        fa="data/genome.fa",
        bam=expand("sorted_reads/{sample}.bam",
                    sample=SAMPLES),
        bai=expand("sorted_reads/{sample}.bam.bai",
                   sample=SAMPLES)
  \end{lstlisting}
  \bcquestion Which are the benefits?
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Input Functions}
  Since we have stored the path to the FASTQ files in the config file, we can also generalize the rule \altverb{bwa_map} to use these paths. This case is different to the rule \altverb{bcftools_call} we modified above. To understand this, it is important to know that \texttt{Snakemake} workflows are executed in three phases.
  \begin{itemize}[<+->]
   \item In the \emph{initialization phase}, the files defining the workflow are parsed and all rules are instantiated.
   \item In the \emph{DAG phase}, the directed acyclic dependency graph of all jobs is built by filling wildcards and matching input files to output files.
   \item In the \emph{scheduling phase}, the DAG of jobs is executed, with jobs started according to the available resources.
  \end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Input Functions - II}
    \begin{alertblock}{Why we cannot do the same all over the Workflow}
    We cannot determine the FASTQ paths for rule \altverb{bwa_map} from the config file in this phase, \emph{because we don’t even know which jobs will be generated from that rule}. Instead, we need to defer the determination of input files to the DAG phase. This can be achieved by specifying an input function instead of a string as inside of the input directive.
  \end{alertblock}
  \begin{lstlisting}[language=Python,style=Python]
def get_bwa_map_input_fastqs(wildcards):
    return config["samples"][wildcards.sample]

rule bwa_map:
    input:
        "data/genome.fa",
        get_bwa_map_input_fastqs
  \end{lstlisting}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{\HandsOn{Adding a new Sample}}
  In the \altverb{data/samples} folder, there is an additional sample \altverb{C.fastq}. Add that sample to the config file and see how \texttt{Snakemake} wants to recompute the part of the workflow belonging to the new sample, when invoking with 
  \begin{lstlisting}[language=Bash, style=Shell]
$ snakemake -n --forcerun bcftools_call
  \end{lstlisting}
  Copy the file XXX as your \texttt{Snakefile}. 
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Rule Parameters}
  \begin{warning}
  	Frequently, party programs cannot be used with their defaults, additional parameters are required.
  \end{warning}
  In our workflow, it is reasonable to annotate aligned reads with so-called read groups, that contain metadata like the sample name. \newline
  To do so, we add to our \altverb{bwa_map}-rule:
  \begin{lstlisting}[style=Plain,basicstyle=\footnotesize]
rule bwa_map:
    input:
        "data/genome.fa",
        get_bwa_map_input_fastqs
    output:
        "mapped_reads/{sample}.bam"
    params:
        rg=r"@RG\tID:{sample}\tSM:{sample}"
    shell:
        "bwa mem -R '{params.rg}' {input} "
        "| samtools view -Sb - > {output}"
  \end{lstlisting}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Rule Parameters}
  This is usually part of the configuration file(s), too.\newline
  In your config file:
  \begin{lstlisting}[language=Python,style=Python]
bwa_map:
   rg=xxx
  \end{lstlisting}
  and in your code:
  \begin{lstlisting}[language=Python,style=Python]
rule bwa_map:
  params:
     rg=config['bwa_map']['rg']
  \end{lstlisting}
  Now, your workflow is configurable!
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Logging}
  \begin{hint}
  	When executing a large workflow, it is usually desirable to store the logging output of each job into a separate file, instead of just printing all logging output to the terminal—when multiple jobs are run in parallel, this would result in chaotic output. - We already observed this!
  \end{hint}
  \pause
  \begin{task}
  	Log into the workflow: Name all rules, which merit gathering logs.
  \end{task}
  \pause
  \begin{docs}
  	In theory \emph{every} rules will profit from logging directives. Only in very rare cases a script or application \emph{cannot} produce output - you will probably not be able to recognize such a case.
  \end{docs}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Logging - II}
  \texttt{Snakemake} offers a \altverb{log}-directive for this purpose.  
  \begin{lstlisting}[language=Python,style=Python]
rule bwa_map:
    input:
        "data/genome.fa",
        get_bwa_map_input_fastqs
    output:
        "mapped_reads/{sample}.bam"
    log: "logs/bwa_mem/{sample.log}"
    # we combine stdout & stdout
    shell:
        "(bwa mem -R '{params.rg}' {input} "
        "| samtools view -Sb - > {output}) 2> {log}"
   \end{lstlisting}
   \begin{task}
     Please try this out.
   \end{task}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Logging - III}
  \begin{question}[Questions]
  	 What did you observe? Why is there a distinction per sample?
  \end{question}
  \pause
  \begin{docs}
  	This rule's output will not clutter the terminal any more. All necessary information is in a log \emph{per} sample: If one attempt to map goes wrong, the specific error can be found in the sample log.
  \end{docs}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Temporary Files}
  Let's face it: Most output files of a workflow, particularly more complex ones(!), do not need to be archived. They will only take up storage until someone takes the \includegraphics[height=\baselineskip]{misc/broom.png}.\newline
  Luckily, \texttt{Snakemake} provides a way to mark a file as ``temporary'' and will delete it, when its not needed any longer.
  \pause
  \begin{question}
  	The output of which rules in our workflow should be marked ``temporary''?
  \end{question}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Temporary Files - Reasoning}
  \begin{center}
    \begin{tabular}{|p{0.2\textwidth}|p{0.1\textwidth}|p{0.65\textwidth}}
      Rule & Temp? & Reason\\\hline
      \altverb{all} & \pause{\color{BrickRed}\bf No} & This rule desingates the final target(s).\\\hline
      \altverb{bwa_map} & \pause{\color{PineGreen}\bf Yes} & Mappings are derived from the intial input and can be created reproducibly again.\\\hline
      \altverb{samtools_sort} & \pause{\color{PineGreen}\bf Yes} & Same reason as with \altverb{bwa_map}\\\hline
      \altverb{samtools_index} & \pause{\color{PineGreen}\bf Yes} & Same reason as with \altverb{bwa_map}\\\hline
      \altverb{bcftools_call} & \pause{\color{BrickRed}\bf No} & This is a result file!\\\hline
      \altverb{plot_quals} & \pause{\color{BrickRed}\bf No} & This is a result file! See \altverb{all}.\\\hline 
    \end{tabular}
  \end{center}
\end{frame} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{\HandsOn{Temporary Files - Put to Work}}
  \texttt{Snakemake}s way to mark outputs as temporary or intermediate is the \altverb{temp()}-function, e.\,g.:
  \begin{lstlisting}[language=Python,style=Python]
rule bwa_map:
    input:
        "data/genome.fa",
        get_bwa_map_input_fastqs
    output:
        @temp(@"mapped_reads/{sample}.bam"@)@
    ...
  \end{lstlisting}
  \pause
  Please run:
  \begin{lstlisting}[language=Bash, style=Shell]
$ du -sh *reads
  \end{lstlisting}
  Add the \altverb{temp()} function to \altverb{bwa_map}- and \altverb{samtools_sort}-rules, re-run the workflow and the \altverb{du}-command. What do you observer?
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{The Command Line}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Parameterization via the Command Line}
  \centering
  \includegraphics[width=0.55\textwidth]{misc/command_line_logo.png}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Executor Selection}
  \texttt{Snakemake} lets you select various executors. Not happy with \mogon? Take another cluster or \lhref{https://snakemake.readthedocs.io/en/stable/executor_tutorial/tutorial.html}{Google Lifescience, Tibanna, Kubernetes, \ldots} \newline
  We may happily select the most prominent HPC batch system, the one running on \mogon, too:
  \begin{lstlisting}[language=Bash, style=Shell]
$ snakemake --slurm
  \end{lstlisting}
  Now, \emph{every} rule will submit its jobs as HPC compute jobs.
  \begin{hint}
  	We will learn how to avoid this, soon-ish.
  \end{hint}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Default Resources for \texttt{SLURM}}
  Without specifying our SLURM-account and a (default) partition, submitting batch jobs will fail. \texttt{Snakemake} allows to define so-called default resources (using \altverb{--default-resources}). With them our minimal command line becomes:
  \begin{lstlisting}[language=Bash, style=Shell, basicstyle=\footnotesize]
$ snakemake --slurm \
> --default-resources slurm_account=m2_jgu-ngstraining \
>                     slurm_partition=smp
  \end{lstlisting}
  \begin{hint}
  	Please notice the missing quotation marks! All arguments belong to one parameter.
  \end{hint}
  \begin{docs}
  	We choose \altverb{slurm_...}-prefixes to distinguish from other non-SLURM accounts and similar stuff.
  \end{docs}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{The ``Beauty'' of Clusters}
  A HPC cluster:
  \begin{itemize}
   \item offers great resources
   \item may hold jobs pending until resources are available!
  \end{itemize}
  \pause
  \texttt{Snakemake} offers a semaphore to throttle resource usage, called \altverb{--jobs/-j}. We can now write \altverb{-j unlimited} in place for \altverb{--cores 1}. Let us try
  \begin{lstlisting}[language=Bash, style=Shell, basicstyle=\footnotesize]
$ snakemake --slurm \
> --default-resources \ 
>   slurm_account=m2_jgu-ngstraining \
>   slurm_partition=smp
> -j unlimited
  \end{lstlisting}
  together. (in a sec.)
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{\texttt{SLURM} supporting Features of \texttt{Snakemake}}
  \texttt{Snakemake} will
  \begin{itemize}[<+->]
   \item hold track of your job status (frequency of checks can be adjusted)
   \item cancel your jobs, when itself is stopped
   \item track resource consumption (generated with \altverb{--report [FILE]})
   \item with \altverb{-j unlimited} we allow for an unlimited jumber of spawned jobs!
  \end{itemize}
  \pause
  \begin{warning}
  	Unlimited number of jobs may yield in I/O contention and too many calls to check the job status. Use with care for both issues there is a remedy, which we will meet later!
  \end{warning}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{\HandsOn{Running the Worklow as Cluster Jobs}}
  Our workflow is {\tiny tiny}. It does not merit cluster execution. Yet, for the purpose of this course, please run (with \altverb{-F} to \emph{enforce} execution):
  \begin{lstlisting}[language=Bash, style=Shell, basicstyle=\footnotesize]
$ snakemake --slurm \
> --default-resources slurm_account=m2_jgu-ngstraining \
>                     slurm_partition=smp \
> -j unlimited @-F@
  \end{lstlisting}
  \begin{question}
  	Observations?
  \end{question}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{The Downside of working with Defaults}
  Ok, this should(!) be running, yet you saw the warnings. 
  \begin{question}
  	Why will a ``real'' workflow fail with all these default settings?
  \end{question}
  \pause
  \begin{itemize}
   \item ``real data'' tend to be biffer - insufficient memory
   \item ``real runs'' tend to take longer - insufficient wall time
   \item ``real runs'' tend to run into I/O issues - insufficient workflows
  \end{itemize}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Cluster Configuration}
  \begin{hint}
  	Best abstract the configuration for a cluster from the workflow!
  \end{hint}
  In addition to a \altverb{config} directory to hold our samples, \texttt{Snakemake} will accept a directory with profile settings, usually ``\altverb{profile}''.
  \pause
  A profile has to adhere to \lhref{https://en.wikipedia.org/wiki/YAML}{\texttt{YAML}-format} and be named \altverb{config.yaml}. An example for a cluster configuration might look like (sorry, no syntax highlighting available):
  \begin{lstlisting}[style=Plain]
set-resources:
    bwa_map:
        runtime: 5
        mem_mb_per_cpu: 1800
  \end{lstlisting}
  \pause
  
  \texttt{Snakemake} \lhref{https://snakemake.readthedocs.io/en/stable/executing/cluster.htmls}{offers many more cluster configuration details}, we will revisit some during this course.

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{\HandsOn{Cluster Execution \textbf{with} Configuration}}
  Please execute the workflow again, now with 
  \begin{lstlisting}[language=Bash, style=Shell, basicstyle=\footnotesize]
$ # first copy the template profile:
$ cp -r ../profile .
$ snakemake --slurm \
> --default-resources slurm_account=m2_jgu-ngstraining \
>                     slurm_partition=smp \
> -j unlimited @--workflow-profile ./profile/ -F@
  \end{lstlisting}
  \begin{question}
  	What do you observe? Which rule still provokes a warning?
  \end{question}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Local Rules}
  \begin{hint}[]
  	Some rules do \emph{not} merit cluster execution!
  \end{hint}
  \pause
  As a rule of thumb this (almost) always includes
  \begin{enumerate}
   \item plotting rules
   \item rules which perform downloads
   \item rules which include remote files (e.\,g. to an archive)
  \end{enumerate}
  \pause
  For such a purpose \texttt{Snakemake} offer the \altverb{localrules} directive.
  \begin{lstlisting}[language=Python,style=Python]
# its useage is (at or near the top of a Snakefile)
localrules: rule_a, rule_b, rule_c, ...
  \end{lstlisting}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{\HandsOn{Implementing ``\texttt{localrules}''}}
  Please add
  \begin{lstlisting}[language=Python,style=Python]
localrules: plot_quals
  \end{lstlisting}
  at the top of your \texttt{Snakefile} and rerun the workflow on this cluster.
  \pause
  \begin{question}
  	Which is the impact on the overall execution time?
  \end{question}
  \pause
  \begin{hint}
  	Rules which do are not compute intensive are best executed locally. The overhead of submitting a job and waiting for it to finish will not be an issue.
  \end{hint}
\end{frame}

