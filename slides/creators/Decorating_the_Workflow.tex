%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Decorating Workflows - Parameterization}
{   
	\usebackgroundtemplate{
		\vbox to \paperheight{\vfil\hbox to \paperwidth{\hfil\includegraphics[height=\paperheight]{logos/decoration.png}\hfil}\vfil}
%https://www.flaticon.com/free-icon/decoration_2788716
%<a href="https://www.flaticon.com/free-icons/decoration" title="decoration icons">Decoration icons created by Freepik - Flaticon</a>

	}
	\frame{
		\frametitle{Further Parameterization of Workflows}
		\begin{mdframed}[tikzsetting={draw=white,fill=white,fill opacity=0.8,
				line width=0pt},backgroundcolor=none,leftmargin=0,
			rightmargin=150,innertopmargin=4pt,roundcorner=10pt]
			\tableofcontents[currentsection,sections={1-4},hideothersubsections]
		\end{mdframed}
	}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{What is this about?}
   \begin{question}[Questions]
   	  \begin{itemize}
         \item How can a workflow be made really usable on a cluster?
         \item How can I avoid changing the workflow source for every new input?
      \end{itemize}
   \end{question}
   \begin{docs}[Objectives]
   	 \begin{enumerate}
                      \item Learn how to make use of configuration files.  
                      \item Learn how to add parameters to your workflow.
     \end{enumerate}
   \end{docs}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Configuration Files}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Command Line vs. Configuration File}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \begin{docs}
  	\Snakemake{} has an extensive command line interface (CLI). \emph{Everything} can be configured on the command line. In addition (almost) everything can be specified in a configuration file.
  \end{docs}
  \pause
  \begin{exampleblock}{Which parameter goes where? Some rules of thumb:}
    \begin{columns}[t]
      \begin{column}{0.5\textwidth}
        The CLI:
        \begin{itemize}
         \item frequently changing parameters
         \item short parameters
         \item default parameters
        \end{itemize}
      \end{column}
      \begin{column}{0.5\textwidth}
        The Config File:
        \begin{itemize}
         \item non-volantile parameters specific to your analysis (those which merit mentioning in paper should always go into a file)
         \item long parameters
         \item otherwise workflow specific parameters
        \end{itemize}
      \end{column}
    \end{columns}
  \end{exampleblock}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{The Configuration File}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{The Configuration File}
  Please copy a sample configuration:
  \begin{lstlisting}[language=Bash, style=Shell]
cp -r /projects/p_nhr_snakemake/solutions/config .
  \end{lstlisting}
  We now have:\newline
            {\tiny \DTsetlength{0.2em}{1em}{0.2em}{0.4pt}{.6pt}
\texttt{\$ tree}
\dirtree{%
.1 /.
.2 config.
.3 config.yaml .
.2 {other stuff}.
}}
 \pause
 \begin{docs}
 	You can store a yaml file with \emph{your} workflow configuration -- which may be combined with the desinger's configuration.
 \end{docs}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Using the Configuration File}
  To point to the configuration file, you can add a flag, e.\,g.:
  \begin{lstlisting}[language=Bash, style=Shell]
$ snakemake ... --configfile ./config/config.yaml  
  \end{lstlisting}
  Or, alternatively in your \altverb{Snakefile}:
  \begin{lstlisting}[language=Python,style=Python]
configfile: "config/config.yaml"
  \end{lstlisting}  
  \begin{question}
  	How can you pick up that info in your \altverb{Snakefile}?!
  \end{question}
\end{frame} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Working with Configuration Data}
  \begin{hint}
  	Remember: \altverb{Snakefile}s are Python files.
  \end{hint}
  \pause
  Given a file \altverb{config.yaml} with contents:
  \begin{lstlisting}[language=Python,style=Python]
samples:
    A: data/samples/A.fastq
    B: data/samples/B.fastq
  \end{lstlisting}
  we can read our samples within our workflow using
  \begin{lstlisting}[language=Python,style=Python]
configfile: "config/config.yaml"

rule bcftools_call:
    input:
        bam=expand("sorted_reads/{sample}.bam", 
        sample=@config["samples"]@),
        ...
  \end{lstlisting}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{A Comparison}
  \begin{lstlisting}[language=Python,style=Python,basicstyle=\footnotesize]
rule bcftools_call:
    input:
        fa="data/genome.fa",
        bam=expand("sorted_reads/{sample}.bam",
                   sample=config["samples"]),
        bai=expand("sorted_reads/{sample}.bam.bai",
                   sample=config["samples"])
  \end{lstlisting}
  To
  \begin{lstlisting}[language=Python,style=Python,basicstyle=\footnotesize]
rule bcftools_call:
    input:
        fa="data/genome.fa",
        bam=expand("sorted_reads/{sample}.bam",
                    sample=samples),
        bai=expand("sorted_reads/{sample}.bam.bai",
                   sample=samples)
  \end{lstlisting}
  \bcquestion Which are the benefits?
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{\HandsOn{Using the Input Function}}
  \begin{task}\footnotesize
  	 Copy \altverb{<++course.pathtosolutions++>/09_Snakefile_config} as the current workflow, already featuring the \altverb{expand()} function - as the Snakefile.\newline
  	 Try the dry-run.
  	 \begin{lstlisting}[language=Bash, style=Shell]
$ snakemake -n -F
  	 \end{lstlisting}
  \end{task}
  \begin{question}
  	What do you observe? 
  \end{question}
  \pause
  \begin{hint}
  	The workflow is now able to take up the configuration - and will deduce all necessary input from the last rule requiring the \altverb{\{sample\}} wildcard.
  \end{hint}
%  \begin{docs}
%  	  Input functions may be \altverb{lambda} functions (oneliners), too. The idea is that complex data mangling can be our-sourced to functions.
%  \end{docs}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
	\frametitle{One more Thing: Input Functions}
	Since we have stored the path to the FASTQ files in the config file, we can also generalize the rule \altverb{bwa_map} to use these paths. This case is different to the rule \altverb{bcftools_call} we modified above. To understand this, it is important to know that \Snakemake{} workflows are executed in three phases.
	\begin{itemize}[<+->]
		\item In the \emph{initialization phase}, the files defining the workflow are parsed and all rules are instantiated.
		\item In the \emph{DAG phase}, the directed acyclic dependency graph of all jobs is built by filling wildcards and matching input files to output files.
		\item In the \emph{scheduling phase}, the DAG of jobs is executed, with jobs started according to the available resources.
	\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
	\frametitle{Input Functions - II}
	\begin{alertblock}{Why we cannot do the same all over the Workflow}
		We cannot determine the FASTQ paths for rule \altverb{bwa_map} from the config file in this phase, \emph{because we don’t even know which jobs will be generated from that rule}. Instead, we need to defer the determination of input files to the DAG phase. This can be achieved by specifying an input function instead of a string as inside of the input directive.
	\end{alertblock}
	\begin{lstlisting}[language=Python,style=Python]
def get_bwa_map_input_fastqs(wildcards):
    return config["samples"][wildcards.sample]
		
rule bwa_map:
    input:
        "data/genome.fa",
        get_bwa_map_input_fastqs # the 'wildcards' argument
                                 # will always be set.
	\end{lstlisting}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
	\frametitle{\HandsOn{Adding a new Sample}}
	\begin{task}\footnotesize
		Copy \altverb{<++course.pathtosolutions++>/10_Snakefile_input_function} as your \altverb{Snakefile}. It contains the input function for the \altverb{bwa_map} rule.
		In the \altverb{data/samples} folder, there is an additional sample \altverb{C.fastq}. Add this sample to the config file and see how \Snakemake{} wants to recompute the part of the workflow belonging to the new sample, when invoking with 
		\begin{lstlisting}[language=Bash, style=Shell]
$ snakemake -j 4 
		\end{lstlisting}
	\end{task}
    \begin{question}[Questions]
    	\footnotesize
    	\begin{itemize}
    		\item The config file is defined in the \altverb{Snakefile} and in the configuration file. Which is better? Do you (strictly speaking) need the \altverb{--configfile} flag?
    		\item Our workflow run without the input function. When could an input function really be useful?
    	\end{itemize}
    \end{question}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
	\frametitle{"Answers" I}
	\begin{question}[We asked \ldots]
		The config file is defined in the \altverb{Snakefile} and in the configuration file. Which is better? Do you (strictly speaking) need the \altverb{--configfile} flag?
	\end{question}
    \pause
    \begin{itemize}[<+->]
    	\item defining the configuration path \emph{within} a \altverb{Snakefile} provides a \emph{default}
    	\item when executing the workflow with different inputs (e.\,g, for different projects) using \altverb{--configfile} lets you select a specific configuration without changing the code!
    \end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
	\frametitle{"Answers" II}
	\begin{question}[We asked \ldots]
    		Our workflow run without the input function. When could an input function really be useful?
	\end{question}
	\pause
	\begin{itemize}[<+->]
		\item good "real world" workflows will allow to use different suffixes \ldots
		\item validate configuration input and \ldots
		\item allow to separate workflow code and data.
	\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Rule Parameters}
  \begin{warning}
  	Frequently, $3^\mathsf{rd}$ party programs cannot be used with their defaults, additional parameters are required.
  \end{warning}
  In our workflow, it is reasonable to annotate aligned reads with so-called read groups, that contain metadata like the sample name. \newline
  To do so, we add to our \altverb{bwa_map}-rule:
  \begin{lstlisting}[style=Plain,basicstyle=\small]
rule bwa_map:
    input:
        "data/genome.fa",
        get_bwa_map_input_fastqs
    output:
        "mapped_reads/{sample}.bam"
    params:
        rg=r"@RG\tID:{sample}\tSM:{sample}"
    shell:
        "bwa mem -R '{params.rg}' {input} "
        "| samtools view -Sb - > {output}"
  \end{lstlisting}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Rule Parameters II}
  This is usually part of the configuration file(s), too.\newline
  If you put this in your config file (the double \altverb{\\} "escape" to \altverb{\t}):
  \begin{lstlisting}[language=Python,style=Python]
bwa_map:
   rg="@RG\\tID:{sample}\\tSM:{sample}"
  \end{lstlisting}
  and in your code:
  \begin{lstlisting}[language=Python,style=Python]
rule bwa_map:
  params:
     @rg=config['bwa_map']['rg']@
  \end{lstlisting}
  You have a configurable workflow! 
  \begin{hint}
  	This is implemented in \altverb{11_Snakefile_rule_params} in your tutorial and solution folder. This should convince you that a configurable workflow is beneficial - in fact \emph{any} software configuration can be stored in a config file.
  \end{hint}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Logging}
  \begin{hint}
  	When executing a large workflow, it is usually desirable to store the logging output of each job into a separate file, instead of just printing all logging output to the terminal—when multiple jobs are run in parallel, this would result in chaotic output. - We already observed this!
  \end{hint}
  \pause
  \begin{task}
  	Look into the workflow: Name all rules, which merit gathering logs.
  \end{task}
  \pause
  \begin{docs}
  	In theory \emph{every} rules will profit from logging directives. Only in very rare cases a script or application \emph{cannot} produce output - you will probably not be able to recognize such a case.
  \end{docs}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
	\frametitle{Logging - I}
	\Snakemake{} offers a \altverb{log}-directive for this purpose. Ordinarily it works like this:
	\begin{lstlisting}[language=Python,style=Python]
rule somename:
    input:
        ...
    output:
        ...
    log: "logs/<somename>/{sample}.log"
    shell:
        "cmd &> {log}"
	\end{lstlisting}
	\begin{docs}\footnotesize
		\begin{itemize}[<+->]
			\item \altverb{&} bundles the \altverb{stderr} and \altverb{stdout} stream and \altverb{>} redirects both to the log file.
			\item The convention is: We use a directory \altverb{logs} for our logfiles.
			\item And a subdirectory with the rule name to differentiate between logs.
		\end{itemize} 
	\end{docs}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Logging - III}
  Rules with a pipe are "special":  
  \begin{lstlisting}[language=Python,style=Python]
rule bwa_map:
    input:
        "data/genome.fa",
        get_bwa_map_input_fastqs
    output:
        "mapped_reads/{sample}.bam"
    log: "logs/bwa_mem/{sample}.log"
    # we combine stdout & stdout
    shell:
        "(bwa mem -R '{params.rg}' {input} "
        "| samtools view -Sb - > {output}) &> {log}"
   \end{lstlisting}
   \begin{docs}[Background]
     Here, we need to put the piped command into \altverb{()} to gather the grouped ouput. 
   \end{docs}
\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{\HandsOn{Logging in Practice}}
  \begin{columns}
  	\begin{column}{0.5\textwidth}
  		\begin{task}
  			Implement the log directive for all rules you consider worth being logged. Test and run. What do you observe?
  		\end{task}
  	    \bcinfo Hints:
  	    \begin{itemize}
  	    	\item take \altverb{11_Snakefile_rule_params} from your tutorial folder as a template.
  	    	\item \bcattention Ignore the plotting rules (with the \altverb{scripts} directive)!
  	    \end{itemize}
  	\end{column}
    \begin{column}{0.5\textwidth}
        \begin{itemize}
        	\item the general syntax is
        	      	\begin{lstlisting}[language=Python,style=Python]
rule somename:
    ...
    log: "logs/<somename>/{sample}.log"
    shell:
        "cmd &> {log}"
        	       \end{lstlisting}
            \item when dealing with piped commands enclose in \altverb{(...)}  before redirecting into the logfile.
            \item when \altverb{stdout} is already used (with \altverb{>}), gather only \altverb{stderr} with \altverb{2>}.
        \end{itemize}
    \end{column}
  \end{columns}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Logging - III}
  \begin{question}[Questions]
  	 What did you observe? Why is there a distinction per sample?
  \end{question}
  \pause
  \begin{docs}[Answers]
  	\begin{itemize}[<+->]
  		\item The \altverb{bwa_map} (and bcftools) output will not clutter the terminal any more. 
  		\item All necessary information is in a log \emph{per} sample: If one attempt to map goes wrong, the specific error can be found in the sample log.
  	\end{itemize}
  \end{docs}
  \only<1->{A working solution is in \altverb{12_Snakemake_logs} in your solutions folder.}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Using Logging Functionality in Python Scripts}
  We know how to use the \altverb{log} directive in a rule, yet our scripts?
  \pause
  \begin{lstlisting}[language=Python,style=Python]
import sys

#somewhere before the actual code starts
sys.stderr = sys.stdout = open(snakemake.log[0], "wt")
  \end{lstlisting}
  \begin{hint}
     Small scripts do not require \altverb{print()} or logging functionality. It would only clutter the terminal. Yet errors can be catched this way, even in job context.
  \end{hint}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Temporary Files}
  Let's face it: Most output files of a workflow, particularly more complex ones(!), do not need to be archived. They will only take up storage until someone takes the \includegraphics[height=\baselineskip]{misc/broom.png}.\newline
  Luckily, \Snakemake{} provides a way to mark a file as ``temporary'' and will delete it, when its not needed any longer.
  \pause
  \begin{question}
  	The output of which rules in our workflow should be marked ``temporary''?
  \end{question}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Temporary Files - Reasoning}
  \begin{center}
    \begin{tabular}{|p{0.2\textwidth}|p{0.1\textwidth}|p{0.65\textwidth}}
      Rule & Temp? & Reason\\\hline
      \altverb{all} & \pause{\color{BrickRed}\bf No} & This rule desingates the final target(s).\\\hline
      \altverb{bwa_map} & \pause{\color{PineGreen}\bf Yes} & Mappings are derived from the intial input and can be created reproducibly again.\\\hline
      \altverb{samtools_sort} & \pause{\color{PineGreen}\bf Yes} & Same reason as with \altverb{bwa_map}\\\hline
      \altverb{samtools_index} & \pause{\color{PineGreen}\bf Yes} & Same reason as with \altverb{bwa_map}\\\hline
      \altverb{bcftools_call} & \pause{\color{BrickRed}\bf No} & This is a result file!\\\hline
      plotting scripts & \pause{\color{BrickRed}\bf No} & These produce result files! See \altverb{all}.\\\hline 
    \end{tabular}
  \end{center}
\end{frame} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{\HandsOn{Temporary Files - Put to Work}}
  \Snakemake{}s way to mark outputs as temporary or intermediate is the \altverb{temp()}-function, e.\,g.:
  \begin{lstlisting}[language=Python,style=Python]
rule bwa_map:
    input:
        "data/genome.fa",
        get_bwa_map_input_fastqs
    output:
        @temp(@"mapped_reads/{sample}.bam"@)@
    ...
  \end{lstlisting}
  \pause
  Implement the \altverb{temp()} function for \altverb{bwa_map}`s output and run the workflow. Please run:
  \begin{lstlisting}[language=Bash, style=Shell]
$ du -sh mapped_reads # measures the size of the folder
$ snakemake -F # after adding temp()
$ du -sh mapped_reads # measures the size of the folder
  \end{lstlisting}
  \pause
  \bcquestion Do you see the benefit of temporary/intermediate files for your data management?
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{The \altverb{protected()} Function}
  \begin{hint}
  	This is just to demonstrate the complement to \altverb{temp()}. Sometimes you might want to protect files from accidental deletion. This can be done with the \altverb{protected()} from \Snakemake.
  \end{hint}
  \pause
  Files labeled "protected" are protected against accidental deletion and overwriting, by withdrawing the right to write. The implementation is as easy as:
  \begin{lstlisting}[language=Python,style=Python]
rule plot_quals:
  ...
  output: 
      protected("calls/quals.png")
  ...
  \end{lstlisting}
  \pause
  \begin{hint}
  	We will \emph{NOT} do this, as it will interfere with our repeated executions.
  \end{hint}	
\end{frame} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Portable Workflow Configuration without Paths?}
  \begin{columns}
  	\begin{column}{0.5\textwidth}
  	  \includegraphics[width=0.9\textwidth]{filesystem/overview.png}
  	\end{column}
    \begin{column}{0.5\textwidth}
    	\begin{question}
    		How can we have a configuration file without file system specifics, run our workflow from \altverb{HOME} and still provide or use a workflow, when our data resides \textbf{elsewhere}?
    	\end{question}
    \end{column}
  \end{columns}
  \pause
  \Snakemake provides the \altverb{--directory} flag for exactly this purpose. You may run
  \begin{lstlisting}[language=Bash, style=Shell]
$ pwd # somewhere /home/.../workflow
$ snakemake --directory /lustre/project/... # example path
  \end{lstlisting}
  \Snakemake will now create and search for all directories relative to \altverb{directory}.
\end{frame} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{The Command Line}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Parametrization via the Command Line}
  \centering
  \includegraphics[width=0.55\textwidth]{misc/command_line_logo.png}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Executor Selection}
  \Snakemake{} lets you select various executors. Not happy with HPC clusters? Pay for a cloud \lhref{https://snakemake.readthedocs.io/en/stable/executor_tutorial/tutorial.html}{Google Lifescience, Tibanna, Kubernetes, \ldots} \newline
  Meanwhile we select the most prominent HPC batch system by:
  \begin{lstlisting}[language=Bash, style=Shell]
$ snakemake --executor slurm
  \end{lstlisting}
  Now, \emph{every} rule will submit its jobs as HPC compute jobs.
  \begin{hint}
  	We will learn how to avoid this, soon-ish.
  \end{hint}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Default Resources for \texttt{SLURM}}
  Without specifying our SLURM-account and a (default) partition, submitting batch jobs will fail. \Snakemake{} allows to define so-called default resources (using \altverb{--default-resources}). With them our minimal command line becomes:
  \begin{lstlisting}[language=Bash, style=Shell, basicstyle=\footnotesize]
$ snakemake --executor slurm \
> --default-resources slurm_partition=<++cluster.partition++><+++ if cluster.account is defined +++> \
>                     slurm_account=<++cluster.account++><+++ endif +++>                      
  \end{lstlisting}
  \begin{hint}
  	Please notice the missing quotation marks! All arguments belong to one parameter -- they can be written in one line.
  \end{hint}
  \begin{docs}
  	We choose \altverb{slurm_...}-prefixes to distinguish from other non-SLURM accounts and similar stuff.
  \end{docs}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{The ``Beauty'' of Clusters}
  A HPC cluster:
  \begin{itemize}
   \item offers great resources
   \item may hold jobs pending until resources are available!
  \end{itemize}
  \pause
  \Snakemake{} offers a semaphore to throttle resource usage, called \altverb{--jobs/-j}. We can now write \altverb{-j unlimited}. Let us try
  \begin{lstlisting}[language=Bash, style=Shell, basicstyle=\footnotesize]
$ snakemake --executor slurm \
> --default-resources slurm_partition=<++cluster.partition++> \ 
<+++ if cluster.account is defined +++>>   slurm_account=<++cluster.account++><+++ endif +++> -j unlimited
  \end{lstlisting}
  together. (in a sec.)
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{\texttt{SLURM} supporting Features of \Snakemake{}}
  \Snakemake{} will
  \begin{itemize}[<+->]
   \item hold track of your job status (frequency of checks can be adjusted)
   \item cancel your jobs, when itself is stopped
   \item track resource consumption (generated with \altverb{--report [FILE]})
   \item with \altverb{-j unlimited} we allow for an unlimited number of spawned jobs!
  \end{itemize}
  \pause
  \begin{warning}
  	"Unlimited" number of jobs may yield in I/O contention and too many calls to check the job status. Use with care for both issues there is a remedy, which we will meet later!
  \end{warning}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{\HandsOn{Running the Worklow as Cluster Jobs}}
  Our workflow is {\tiny tiny}. It does not merit cluster execution. Yet, for the purpose of this course, please run (with \altverb{-F} to \emph{enforce} execution):
  \begin{lstlisting}[language=Bash, style=Shell, basicstyle=\footnotesize]
$ snakemake --executor slurm \
> --default-resources slurm_partition=<++cluster.partition++> \
> <+++ if cluster.account is defined +++>      slurm_account=<++cluster.account++><+++ endif +++> -j unlimited @-F@
  \end{lstlisting}
  \begin{question}
  	Observations?
  \end{question}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{The Downside of working with Defaults}
  Ok, this should(!) be running, yet you saw warnings. 
  \begin{question}
  	Why will a ``real'' workflow fail with all these default settings?
  \end{question}
  \pause
  \begin{itemize}
   \item ``real data'' tend to be different - insufficient memory
   \item ``real runs'' tend to take longer - insufficient wall time
   \item ``real runs'' tend to run into I/O issues - insufficient workflows
  \end{itemize}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
	\frametitle{The \Snakemake{} \texttt{resources} Section}
	\Snakemake{} rules provide an additional \altverb{resources} section:
	\begin{lstlisting}[language=Python,style=Python]
rule <name>:
	...
	resources:
		partition='parallel',
		mem_mb=1800,
		cpus_per_task=4
	\end{lstlisting}
	\begin{hint}
		Note the \textbf{,}!
	\end{hint}
	\pause
	\begin{docs}
		You \emph{may} define \emph{any} resource keyword within any rule.
	\end{docs}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
	\frametitle{The \Snakemake{} \texttt{resources} Section - its Downside}
	\begin{block}{Every Resource Spec needs a Change per Rule???}
		You might have noticed, this specification per rule is most untidy. \Snakemake's design principle is: ship workflows which run \emph{everywhere} \& \emph{every time}.
		\newline \pause
		Relax: Every bit we can specify:
		\begin{itemize}
			\item in a \altverb{Snakefile},
			\item on the command line,
			\item and re-usable in configuration files!
		\end{itemize}
	\end{block}
\end{frame} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Cluster Configuration}
  \begin{hint}
  	Best abstract the configuration for a cluster from the workflow!
  \end{hint}
  In addition to a \altverb{config} directory to hold our samples, \Snakemake{} will accept a directory with profile settings, usually ``\altverb{profile}''.
  \pause
  A profile has to adhere to \lhref{https://en.wikipedia.org/wiki/YAML}{\texttt{YAML}-format} and be named \altverb{config.yaml}. An example for a cluster configuration might look like (sorry, no syntax highlighting available):
  \begin{lstlisting}[style=Plain]
set-resources:
    bwa_map:
        runtime: 5
        mem_mb_per_cpu: 1800
  \end{lstlisting}
  \pause
  
  \Snakemake{} \lhref{https://snakemake.readthedocs.io/en/stable/executing/cluster.htmls}{offers many more cluster configuration details}, we will revisit some during this course.

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{\HandsOn{Cluster Execution \textbf{with} Configuration}}
  Please execute the workflow again, now with 
  \begin{lstlisting}[language=Bash, style=Shell, basicstyle=\footnotesize]
$ # first copy the template profile:
$ cp -r ../tasks/tutorial/profile .
$ # now, the defaults are satisfied
$ snakemake --executor slurm \
> -j unlimited \
> @--workflow-profile ./profile/ -F@
  \end{lstlisting}
  \begin{question}
  	What do you observe? Which rule still provokes a warning?
  \end{question}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Local Rules}
  \begin{hint}[]
  	Some rules do \emph{not} merit cluster execution!
  \end{hint}
  \pause
  As a rule of thumb this (almost) always includes
  \begin{enumerate}
   \item plotting rules
   \item rules which perform downloads
   \item rules which include remote files (e.\,g. to an archive)
  \end{enumerate}
  \pause
  For such a purpose \Snakemake{} offers the \altverb{localrules} directive.
  \begin{lstlisting}[language=Python,style=Python]
# its useage is (at or near the top of a Snakefile)
localrules: rule_a, rule_b, rule_c, ...
  \end{lstlisting}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{\HandsOn{Implementing ``\texttt{localrules}''}}
  Please add
  \begin{lstlisting}[language=Python,style=Python]
localrules: plot_quals, plot_positions
  \end{lstlisting}
  at the top of your \Snakemake{} and rerun the workflow on this cluster.
  \pause
  \begin{question}
  	Which is the impact on the overall execution time?
  \end{question}
  \pause
  \begin{hint}
  	Rules which do are not compute intensive are best executed locally. The overhead of submitting a job and waiting for it to finish will not be an issue.
  \end{hint}
\end{frame}

