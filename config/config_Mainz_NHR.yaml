instructor:
  name: "Dr. Christian Meesters"
  affiliation: "Johannes Gutenberg Universität Mainz"
  affiliation2: "NHR SüdWest" # may be empty
  
layout:
  beamertheme: "CambridgeUS" # you can choose any, the slides are tested
                             # with 'CambridgeUS'
  colortheme: "beaver"       # you can choose any, the slides are tested with
                             # 'beaver'
  # choose any preconfigured color or those from the preamble
  beamercolor_structure:  "fg=UniRot" 
  beamercolor_title:      "fg=UniRot"
  beamercolor_title_head: "fg=UniRot"

  beamercolor_block_title: "bg=UniRot!20,fg=darkred"
  beamercolor_block_body:  "fg=black, bg=plightgrey2"

  beamercolor_block_title_alerted: "fg=white,bg=UniRot"
  beamercolor_block_title_example: "fg=white,bg=PineGreen!80"

course:
  date: "datestring" # maybe: "\today"
  #title: "" # specifiy your title here, else a default is used. 
  #subtitle: "" # specifiy your subtitle here, else a default is used. 
  # Editors recommendations are a matter of taste and technological
  # setups (e.g. on-demand setups). Hence, specify an editor-slide,
  #  here:
  editorfile: "common/editor_gedit_mainz.tex"
  # The next line indicates the slides explaining
  # a condarc file on a cluster, copy and adjust
  # for your cluster.
  condarcfile: "common/condarc_mogon.tex"
  # the same for admins:
  condarc_admins_file: "admin/condarc_mogon.tex"
  # We provide a common software stack to avoid long
  # installation sessions.
  softwarepath: "/lustre/project/m2\_jgu-ngstraining/software"
  # these are the path names to contain sample data
  # see the README for explanations.
  pathtosetup: "/lustre/project/m2\_jgu-ngstraining/workflows"
  pathtosolutions: "/lustre/project/hpckurs/m2\_jgu-ngstraining"
  # This is the selected slide to explain the 'Hello World' script
  # to introduce SLURM. It requires different account and partition
  # settings on every cluster.
  hello_world_script: "common/Hello_World_HPC_MogonII.tex"
cluster:
  # the cluster account and default partition
  account: "m2_jgu-ngstraining"
  partition: "smp"
  # the local and remote storage prefixes on this cluster
  remote-job-local-storage-prefix: "/localscratch/$SLURM_JOB_ID"
  local-storage-prefix: "/dev/shm/$USER/snakemake"
